+++
title = "What our writing does"
date = 2024-02-25
draft = false
+++

I read [this review](https://lareviewofbooks.org/article/computation-de-texte/), by James Edward Draney, of Dennis Tenen's _Plain Text: The Poetics of Computation_ and, for being from late 2017, I was struck by two statements.

The first struck me as ahead of its time in recognizing the low-impact fad-nature of "digital humanities": "Digital photography, digital clocks, and digital humanities already ring archaic in their futuristic ambition, going the way of e- or i- anything, the way of retro suffixes such as -bot, -mat, -lux, and -tron."
I also appreciate this similar line:
"Despite the general public's familiarity with computing interfaces, it still seems illogical to refer to the public as 'digital natives' if they remain ignorant of the deep levels of code governing such inscription technologies."

By constrast, the second statement—an argument at the core of the book, really—rung, _in part_, overblown in just how drastic a shift it thinks has taken place with the networked computational substrate of so much writing.
Draney gives a helpful précis of Friedrich Kittler's media-historical claim that "we simply do not know what our writing does" (Kittler).
The gist is that since Intel's engineers designed the first integrated microprocessor in the early 1970s, writing has become automated—not in the sense of "automatic writing" (a technique whereby a poet writes ceaselessly so as to avoid as much conscious intent as possible) but, rather, insofar as our writing has gradually relocated from paper to "rearranged lines of code on a word processor" (Draney).
Once it's computational, the production, recording, and duplication and distribution of human writing is irrevocably transformed because the media of writing are out of mind and, without access to the source code or an electron microscope, out of sight.

Tenen begins from Kittler's primse, but he takes a slightly different view with regards to literature: not only does it continue to exist and have new things to express, literature and especially literary theory "are far more effective as political tools than any banal, agit-prop list of digital privacy breaches."
I am instinctively in agreement, and I was pleased to see Viktor Shklovsky referenced.
However, I find the argument strange:

"At the heart of Tenen’s book is the surreal realization that our modern reading and writing systems — word processors, PDFs, ebooks — have more in common with digital smoke detectors than they do with leather-bound books, which is to say that they are all governed by invisible lines of code. Unlike words written in ink on paper (where what you see is what you get), the digital stage of textuality is unstable, beholden to the laws and constraints of computer code, legal contracts, and encrypted protections."

While I grant that the change in supporting media changes what is done _with_ writing, this claim is somewhat like saying that a book or handwritten page of notes has more in common with the porosity of wood pulp (because paper) and sheen of garment dyes (because ink) than with the etchings on clay tablets.
It is reductive.
In a way, our writing goes on as it has, indifferent to the media that afford its existence.
In at least one way, we know more about what our writing does than before, on account of being able to track who reads computational (especially web-based) text and for how long, which is impossible with analog texts.

Granted, I am twisting Draney's words a bit, since he's talking about "reading and writing _systems_," which could be taken to mean the stack of web technologies I'm using to serve up this text as opposed to what is being done with it.
But then, why talk about literature at all?
That sort of comparative technology would be right at home not in a text by Kittler but in one by Gilbert Simondon.
One could imagine an analysis of the piston converter of a fountain pen that traces its mechanical vacuum pump to an oil rigging or well pump.
But would that entail that readers and writers of non-computational means are somehow nonconsciously in tune with a Pneumatic Age of technology?
Of course not.
Thus, I consider the claim—that "word processors, PDFs, ebooks," and even the extraordinarily extensible text editor and introspective LISP environment I use to write (emacs), "have more in common with digital smoke detectors than they do with leather-bound books"—to be a hollow point premised on an arbitrarily narrow basis of comparison.

But I said the argument was overblown "in part" and not in full.
Seven or eight years ago, Tenen and Draney likely knew little of machine learning and almost certainly had no idea about large-language models—except to the extent that LLMs have long featured conceptually, if not in the same words, in certain subsets of humanities research (what's called "structuralism" being the main one).
Today, a kind of writing inseparable from its computational media is taking place.
Maybe it's language without writing, or language through a significantly different kind of writing.
But even that is not entirely automated through algorithms, since a global workforce is employed to train these models.
(For example, since I have a PhD from a literature program, I received an automated message about working for a company focused on improving "advanced English" text generation. Here's [the job post](https://boards.greenhouse.io/outlier/jobs/4354675005?gh_src=6b3760615us&li_fat_id=f3bdcce0-76e3-41bf-bac0-c35046a7c031).)
That's to say nothing of the engineering and statistical work that goes into training LLMs.

Perhaps Tenen's book has become more accurate and thus more relevant in the intervening years since its publication.
Or maybe, since LLMs are souped-up autocomplete engines reproducing content that was already made to fit various generic molds (and has been in a feedback loop with earlier forms of computationally generated text), an even greater proportion of "written" text arrives already known and thus goes unread.

To condense the point: writing has always been "automated" because it depends in part on repeated forms, on habits of style and production.
I'd like to think that the glut of automatism will redound to a greater appreciation, and if not then certainly a need, for the _enstrangement_ that art effects.
To recur to the Shklovsky reference, in order for our habits of perception to be interrupted, what's needed is not literary criticism but literature, which was Shklovsky's point all the way down to the style of his own criticism.
